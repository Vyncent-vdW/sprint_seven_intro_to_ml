{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Allan Jeeboo \n",
    "### Preferred Name: Vyncent S. A. van der Wolvenhuizen \n",
    "### Affiliation: Student at TripleTen \n",
    "### Email: vanderwolvenhuizen.vyncent@proton.me\n",
    "### Date Started: 2025-03-12 \n",
    "### Last Updated: 2025-03-17 16:17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Introduction\n",
    "This project places us in the role of developing a model that analyzes subscribers' behavior for the telecommunications company Megaline. This model will recommend one of their newer plans: Smart or Ultra. \n",
    "\n",
    "We have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis sprint). For this classification task, we need to develop a model that will pick the right plan. Since we’ve already performed the data preprocessing step, we can move straight to creating the model. \n",
    "\n",
    "We'll create a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. We'll check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Module & Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows, columns: (3214, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "\n",
    "display(df.head()) \n",
    "print(f'rows, columns: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Description\n",
    "This dataset contains monthly behavior information regarding users.\n",
    "- сalls: Number of calls.\n",
    "- minutes: Total call duration in minutes.\n",
    "- messages: Number of text messages.\n",
    "- mb_used: Internet traffic used in MB.\n",
    "- is_ultra: Plan for the current month (Ultra - 1, Smart - 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll be testing three types of models:  \n",
    "- Decision Tree Classifier \n",
    "- Random Forest Classifier \n",
    "- Logistic Regression\n",
    "\n",
    "We need to establish what our features and target are. Because we want to see who is already an ultra member, is_ultra will be our target. \"is_ultra\" is not numerical (it has binary representation, but it's classifying users into two groups.), so we'll use classification models. Everything except for \"is_ultra\" will be our features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to establish the features and targets. Afterwards, we'll split the data set to obtain a test set; from the remainder of the initial set, we'll split that once more to obtain a validation set. I've chosen a test size and validation size of 0.2, so our data split has a ratio of 3:1:1. Throughout this project, we'll pass the arbitrary argument of 12345 to our random_state parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature rows, columns: (3214, 4)\n",
      "target rows: (3214,)\n",
      "test rows, columns: (643, 5)\n"
     ]
    }
   ],
   "source": [
    "features = df.drop('is_ultra', axis= 1) \n",
    "target = df['is_ultra']\n",
    "train_valid, test = train_test_split(df, test_size= 0.2, random_state= 12345)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size= 0.2, random_state= 12345)\n",
    "\n",
    "print(f'feature rows, columns:', features.shape)\n",
    "print(f'target rows:', target.shape)\n",
    "print(f'test rows, columns:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tune the model and see which depth yields the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for depth 1: 0.7480559875583204\n",
      "Validation accuracy for depth 2: 0.7807153965785381\n",
      "Validation accuracy for depth 3: 0.7838258164852255\n",
      "Validation accuracy for depth 4: 0.7791601866251944\n",
      "Validation accuracy for depth 5: 0.7853810264385692\n",
      "Validation accuracy for depth 6: 0.7822706065318819\n",
      "Validation accuracy for depth 7: 0.7791601866251944\n",
      "Validation accuracy for depth 8: 0.7729393468118196\n",
      "Validation accuracy for depth 9: 0.7791601866251944\n",
      "Accuracy on the train set: 0.8638661999222093\n",
      "Best Decision Tree Classifier accuracy: 0.7853810264385692 with depth 5\n",
      "Accuracy on the test set: 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "best_dtc_accuracy = 0 \n",
    "best_dtc_depth = 0 \n",
    "best_dtc_model = None\n",
    "\n",
    "for depth in range (1, 10): \n",
    "    decision_tree_model = DecisionTreeClassifier(random_state= 12345, max_depth= depth) \n",
    "    decision_tree_model.fit(features_train, target_train)\n",
    "    predictions_valid = decision_tree_model.predict(features_valid) \n",
    "    print(f'Validation accuracy for depth {depth}: {accuracy_score(target_valid, predictions_valid)}')\n",
    "    if accuracy_score(target_valid, predictions_valid) > best_dtc_accuracy: \n",
    "        best_dtc_accuracy = accuracy_score(target_valid, predictions_valid)\n",
    "        best_dtc_depth = depth\n",
    "        best_dtc_model = decision_tree_model\n",
    "\n",
    "test_features = test.drop('is_ultra', axis = 1)\n",
    "test_target = test['is_ultra']\n",
    "train_pedictions = decision_tree_model.predict(features_train)\n",
    "test_predictions = decision_tree_model.predict(test_features)\n",
    "\n",
    "print(f'Accuracy on the train set: {accuracy_score(target_train, train_pedictions)}')\n",
    "print(f'Best Decision Tree Classifier accuracy: {best_dtc_accuracy} with depth {best_dtc_depth}')\n",
    "print(f'Accuracy on the test set: {accuracy_score(test_target, test_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sets have an accuracy, rounded to three decimal places, of:  \n",
    "- Training: 86.888%\n",
    "- Validation: 78.538%\n",
    "- Test: 78.849%\n",
    "\n",
    "Usually the test and validation sets have about the same value, and seeing as the difference here is a mere 0.311%, that's a good sign.\n",
    "In addition to that, a max depth of 5 appears to yield the best validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifiers have the highest degree of accuracy due to the fact that it generates a specified quantity of independent trees, then votes on the best model. The downside though is that due to the fact that it's generating multiple trees, it has a low speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the validation set (n_estimators = 20): 0.7884914463452566\n",
      "Accuracy on the train set: 0.9906651108518086\n",
      "Accuracy on the test set: 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "best_score = 0 \n",
    "best_est = 0 \n",
    "for est in range(1, 100): \n",
    "    random_forest_model = RandomForestClassifier(random_state= 12345, n_estimators= est) \n",
    "    random_forest_model.fit(features_train, target_train)\n",
    "    score_valid = random_forest_model.score(features_valid, target_valid)\n",
    "    if score_valid > best_score: \n",
    "        best_score = score_valid\n",
    "        best_est = est\n",
    "\n",
    "print(\"Accuracy of the best model on the validation set (n_estimators = {}): {}\".format(best_est, best_score))\n",
    "\n",
    "final_model = RandomForestClassifier(random_state=12345, n_estimators=best_est) # change n_estimators to get best model\n",
    "final_model.fit(features_train, target_train)\n",
    "train_predictions = final_model.predict(features_train)\n",
    "test_predictions = final_model.predict(test_features)\n",
    "print(f'Accuracy on the train set: {accuracy_score(target_train, train_predictions)}')\n",
    "print(f'Accuracy on the test set: {accuracy_score(test_target, test_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sets have an accuracy, rounded to three decimal places, of:  \n",
    "- Training: 99.067%\n",
    "- Validation: 78.849%\n",
    "- Test: 79.849%\n",
    "\n",
    "In addition to that, the best estimate in range 1 to 100 appears to be n_estimators= 20. \n",
    "\n",
    "The validation set for the Random Forest typically tends to yields a higher accuracy than that of the Decision Tree, and it just barely does so in this test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set: 0.7016725009723843\n",
      "Accuracy of the logistic regression model on the validation set: 0.702954898911353\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state= 12345, solver= 'liblinear')\n",
    "logistic_model.fit(features_train, target_train)  # train model on training set\n",
    "score_train = logistic_model.score(features_train, target_train) # calculate accuracy score on training set  \n",
    "score_valid = logistic_model.score(features_valid, target_valid)\n",
    "     # calculate accuracy score on validation set  \n",
    "\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the training set:\",\n",
    "    score_train,\n",
    ")\n",
    "print(\n",
    "    \"Accuracy of the logistic regression model on the validation set:\",\n",
    "    score_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our sets have an accuracy, rounded to three decimal places, of:  \n",
    "- Training: 70.167%\n",
    "- Validation: 70.295%\n",
    "\n",
    "The logistic regression model has the lowest accuracy of all tested model types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Conclusion\n",
    "\n",
    "Through this project, we have tested three models and they've yielded the following validation accuracies:\n",
    " - Decision Tree Classifier: 78.538%. A max depth of 7 yielded the best results.\n",
    " - Random Forest Classifier: 78.849%. n_estimators= 20 yielded the best results. \n",
    " - Logistic Regression: 70.295% \n",
    "\n",
    "Validation accuracy reflects how often the model reaches the correct answer. Seeing as there are two possible answers to whether or not Megaline users are ultra users or not, our sanity check threshold is 50%; i.e., through random chance the result would be right half of the time. All of our models produced results above that, but for the 75% threshold mentioned at the beginning of this project, the Logistic Regression model failed to exceed that. That being said, the Random Forest Classifier appears to be the best model to use in regards to recommending plans to Megaline customers. One downside that needs to be reiterated is that because this type of model is processing multiple trees, it is the slowest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
